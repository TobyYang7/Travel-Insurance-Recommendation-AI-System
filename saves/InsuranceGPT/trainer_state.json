{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.993377483443709,
  "eval_steps": 100,
  "global_step": 678,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "grad_norm": 2.8102980896096654,
      "learning_rate": 2.5e-05,
      "loss": 3.4889,
      "step": 10
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.683728710550092,
      "learning_rate": 5e-05,
      "loss": 2.9051,
      "step": 20
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6057674970305643,
      "learning_rate": 4.997151111381707e-05,
      "loss": 2.2894,
      "step": 30
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6467115906438414,
      "learning_rate": 4.988610938459917e-05,
      "loss": 2.2021,
      "step": 40
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8311950897480177,
      "learning_rate": 4.9743989452357756e-05,
      "loss": 2.1483,
      "step": 50
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.799264763244853,
      "learning_rate": 4.954547522417877e-05,
      "loss": 2.163,
      "step": 60
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7873579519404368,
      "learning_rate": 4.929101913600238e-05,
      "loss": 2.1054,
      "step": 70
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.3559035619525037,
      "learning_rate": 4.8981201121471356e-05,
      "loss": 2.0427,
      "step": 80
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7282912037448914,
      "learning_rate": 4.861672729019797e-05,
      "loss": 1.9622,
      "step": 90
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0497524926028197,
      "learning_rate": 4.81984283184619e-05,
      "loss": 2.0331,
      "step": 100
    },
    {
      "epoch": 0.44,
      "eval_loss": 1.711480736732483,
      "eval_runtime": 150.1113,
      "eval_samples_per_second": 2.685,
      "eval_steps_per_second": 0.673,
      "step": 100
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8666793155211042,
      "learning_rate": 4.772725755600682e-05,
      "loss": 2.1126,
      "step": 110
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.0597657840088512,
      "learning_rate": 4.720428885325069e-05,
      "loss": 1.9906,
      "step": 120
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7336607766808005,
      "learning_rate": 4.663071411386151e-05,
      "loss": 2.057,
      "step": 130
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.8464616992746797,
      "learning_rate": 4.600784057827671e-05,
      "loss": 1.9385,
      "step": 140
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1849887589666455,
      "learning_rate": 4.5337087844357226e-05,
      "loss": 2.0753,
      "step": 150
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.974470827372214,
      "learning_rate": 4.4619984631966524e-05,
      "loss": 1.982,
      "step": 160
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.66107135018114,
      "learning_rate": 4.3858165298848556e-05,
      "loss": 2.017,
      "step": 170
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.8161243896813543,
      "learning_rate": 4.305336611574517e-05,
      "loss": 2.0816,
      "step": 180
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.2448490913525674,
      "learning_rate": 4.220742130924257e-05,
      "loss": 2.1655,
      "step": 190
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.3807828991748596,
      "learning_rate": 4.132225888136552e-05,
      "loss": 2.0417,
      "step": 200
    },
    {
      "epoch": 0.88,
      "eval_loss": 1.6613609790802002,
      "eval_runtime": 149.2634,
      "eval_samples_per_second": 2.7,
      "eval_steps_per_second": 0.677,
      "step": 200
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3571844848985344,
      "learning_rate": 4.03998962154469e-05,
      "loss": 2.1089,
      "step": 210
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.148449899704228,
      "learning_rate": 3.944243547828742e-05,
      "loss": 2.0077,
      "step": 220
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.981561553821281,
      "learning_rate": 3.845205882908432e-05,
      "loss": 1.9005,
      "step": 230
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.0852038227986698,
      "learning_rate": 3.74310234460486e-05,
      "loss": 1.8528,
      "step": 240
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.0630272803021314,
      "learning_rate": 3.638165638204553e-05,
      "loss": 1.8891,
      "step": 250
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.1024451310070467,
      "learning_rate": 3.530634926098316e-05,
      "loss": 1.8531,
      "step": 260
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.1833991378582056,
      "learning_rate": 3.4207552827036176e-05,
      "loss": 1.9784,
      "step": 270
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.7075632556794906,
      "learning_rate": 3.308777135912818e-05,
      "loss": 1.95,
      "step": 280
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.7868688406238138,
      "learning_rate": 3.194955696340228e-05,
      "loss": 1.9733,
      "step": 290
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.4806955171565566,
      "learning_rate": 3.079550375668821e-05,
      "loss": 1.9037,
      "step": 300
    },
    {
      "epoch": 1.32,
      "eval_loss": 1.6363567113876343,
      "eval_runtime": 148.5525,
      "eval_samples_per_second": 2.713,
      "eval_steps_per_second": 0.68,
      "step": 300
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.3839333969241838,
      "learning_rate": 2.9745486910657993e-05,
      "loss": 1.8879,
      "step": 310
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.7303780434369134,
      "learning_rate": 2.856861121188735e-05,
      "loss": 1.8563,
      "step": 320
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.9008857057280315,
      "learning_rate": 2.7383602252424985e-05,
      "loss": 1.8877,
      "step": 330
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.2302264982132425,
      "learning_rate": 2.619316079910063e-05,
      "loss": 1.9895,
      "step": 340
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.4466998406423255,
      "learning_rate": 2.5e-05,
      "loss": 1.9387,
      "step": 350
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.8212002465973118,
      "learning_rate": 2.3806839200899377e-05,
      "loss": 1.7564,
      "step": 360
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.8705419155643634,
      "learning_rate": 2.261639774757503e-05,
      "loss": 1.8857,
      "step": 370
    },
    {
      "epoch": 1.68,
      "grad_norm": 2.125529171523736,
      "learning_rate": 2.143138878811265e-05,
      "loss": 1.7182,
      "step": 380
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.8998601607575494,
      "learning_rate": 2.025451308934201e-05,
      "loss": 2.0109,
      "step": 390
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.7181946036789086,
      "learning_rate": 1.9088452881489787e-05,
      "loss": 1.8929,
      "step": 400
    },
    {
      "epoch": 1.77,
      "eval_loss": 1.6176114082336426,
      "eval_runtime": 148.9393,
      "eval_samples_per_second": 2.706,
      "eval_steps_per_second": 0.678,
      "step": 400
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.88165188455925,
      "learning_rate": 1.793586574507951e-05,
      "loss": 2.0252,
      "step": 410
    },
    {
      "epoch": 1.85,
      "grad_norm": 2.602565748300431,
      "learning_rate": 1.6799378554010773e-05,
      "loss": 1.943,
      "step": 420
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.8955626958110505,
      "learning_rate": 1.5681581488622367e-05,
      "loss": 1.8426,
      "step": 430
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.4436570119835606,
      "learning_rate": 1.4585022132384008e-05,
      "loss": 1.7808,
      "step": 440
    },
    {
      "epoch": 1.99,
      "grad_norm": 1.7742746970663146,
      "learning_rate": 1.3512199665671094e-05,
      "loss": 1.8877,
      "step": 450
    },
    {
      "epoch": 2.03,
      "grad_norm": 2.267706592448622,
      "learning_rate": 1.2465559169855535e-05,
      "loss": 1.8671,
      "step": 460
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.9666293215430724,
      "learning_rate": 1.1447486054694112e-05,
      "loss": 1.7659,
      "step": 470
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.9913867119787598,
      "learning_rate": 1.046030062171512e-05,
      "loss": 1.7347,
      "step": 480
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.9668510572717584,
      "learning_rate": 9.506252775993882e-06,
      "loss": 1.8488,
      "step": 490
    },
    {
      "epoch": 2.21,
      "grad_norm": 1.850640525910796,
      "learning_rate": 8.587516898369589e-06,
      "loss": 1.6542,
      "step": 500
    },
    {
      "epoch": 2.21,
      "eval_loss": 1.608199954032898,
      "eval_runtime": 148.5049,
      "eval_samples_per_second": 2.714,
      "eval_steps_per_second": 0.68,
      "step": 500
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.7051661181167201,
      "learning_rate": 7.706186889790209e-06,
      "loss": 1.8738,
      "step": 510
    },
    {
      "epoch": 2.3,
      "grad_norm": 2.3324514893478456,
      "learning_rate": 6.86427139908008e-06,
      "loss": 1.9227,
      "step": 520
    },
    {
      "epoch": 2.34,
      "grad_norm": 1.5282657134907212,
      "learning_rate": 6.063689245006443e-06,
      "loss": 1.9137,
      "step": 530
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.081009315051381,
      "learning_rate": 5.306265043078693e-06,
      "loss": 1.727,
      "step": 540
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.8738824032520314,
      "learning_rate": 4.593725047047293e-06,
      "loss": 1.7736,
      "step": 550
    },
    {
      "epoch": 2.47,
      "grad_norm": 1.6911937009528761,
      "learning_rate": 3.927693214580075e-06,
      "loss": 1.7799,
      "step": 560
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.1618319095674683,
      "learning_rate": 3.3096875060825845e-06,
      "loss": 1.8211,
      "step": 570
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.53663585186864,
      "learning_rate": 2.741116425097995e-06,
      "loss": 1.7206,
      "step": 580
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.0530698248923374,
      "learning_rate": 2.22327580817136e-06,
      "loss": 1.7414,
      "step": 590
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.2580243334940167,
      "learning_rate": 1.7573458714944063e-06,
      "loss": 1.7774,
      "step": 600
    },
    {
      "epoch": 2.65,
      "eval_loss": 1.6075913906097412,
      "eval_runtime": 148.5509,
      "eval_samples_per_second": 2.713,
      "eval_steps_per_second": 0.68,
      "step": 600
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.5855020836380866,
      "learning_rate": 1.3443885210619428e-06,
      "loss": 1.9246,
      "step": 610
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.254262168880888,
      "learning_rate": 9.85344932470364e-07,
      "loss": 1.8086,
      "step": 620
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.427857659436221,
      "learning_rate": 6.810334058740736e-07,
      "loss": 1.8651,
      "step": 630
    },
    {
      "epoch": 2.83,
      "grad_norm": 3.109808211442538,
      "learning_rate": 4.3214750098869995e-07,
      "loss": 1.8221,
      "step": 640
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.4015143494731563,
      "learning_rate": 2.392544563915883e-07,
      "loss": 1.8852,
      "step": 650
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.0265105876207876,
      "learning_rate": 1.0279389672218365e-07,
      "loss": 1.8882,
      "step": 660
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.2427774375480327,
      "learning_rate": 2.3076830728713252e-08,
      "loss": 1.7918,
      "step": 670
    },
    {
      "epoch": 2.99,
      "step": 678,
      "total_flos": 210517917171712.0,
      "train_loss": 1.9620671736455597,
      "train_runtime": 4836.2375,
      "train_samples_per_second": 2.246,
      "train_steps_per_second": 0.14
    }
  ],
  "logging_steps": 10,
  "max_steps": 678,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "total_flos": 210517917171712.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
